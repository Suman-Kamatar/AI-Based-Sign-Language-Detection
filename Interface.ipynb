{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4cce17-21b4-4951-a4a1-6ed72dea5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84fe9a5-1aa7-4143-a112-bdbd358c9727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('sign_language_model.h5')\n",
    "with open(\"history.pkl\", 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07215094-3558-47bd-aab2-9cb032f9c51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.9838705e-03, 2.1297892e-03, 4.7142452e-04, 3.1762014e-04,\n",
       "        5.6273346e-03, 4.7914276e-04, 2.4799127e-04, 1.9809788e-03,\n",
       "        4.4221613e-03, 5.9636956e-04, 1.2796443e-02, 6.6012573e-01,\n",
       "        1.7931102e-03, 1.1119507e-02, 8.4824127e-04, 4.6780604e-04,\n",
       "        4.6244254e-03, 1.4709410e-01, 1.9394903e-03, 4.3814073e-04,\n",
       "        1.2903235e-02, 9.7729045e-04, 8.1076520e-04, 3.4229856e-02,\n",
       "        1.4906668e-02, 9.4567932e-04, 1.3164855e-02, 4.7845920e-03,\n",
       "        8.6246673e-03, 1.0652085e-02, 2.2201026e-02, 5.6360890e-03,\n",
       "        2.6833036e-03, 7.5856452e-03, 3.9055446e-04]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the model with dummy data to initialize its layers\n",
    "dummy_input = np.random.rand(1, 64, 64, 3).astype('float32')  # Adjust to match input shape\n",
    "model.predict(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be9be1a-fdae-40dd-bbb4-bd2a8164ac05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://278c28f093234f7d1f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://278c28f093234f7d1f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"sign_language_model_1.h5\")\n",
    "\n",
    "# Load the label encoder to decode predictions\n",
    "# Replace with the actual labels in your dataset\n",
    "label_encoder = LabelEncoder()\n",
    "labels = ['1' ,'2', '3' ,'4' ,'5' ,'6', '7', '8', '9', 'A' ,'B', 'C' ,'D' ,'E', 'F', 'G' ,'H' ,'I',\n",
    " 'J' ,'K', 'L' ,'M', 'N' ,'O', 'P', 'Q', 'R' ,'S' ,'T' ,'U', 'V' ,'W' ,'X', 'Y', 'Z']   # Replace ... with all class labels\n",
    "label_encoder.fit(labels)\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (64, 64)\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    # Convert PIL image to numpy array\n",
    "    img_array = np.array(image)\n",
    "    # Resize the image to match the model input size\n",
    "    img_array = cv2.resize(img_array, IMG_SIZE)\n",
    "    img_array = img_to_array(img_array)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize\n",
    "    return img_array\n",
    "\n",
    "# Function to predict the sign\n",
    "def predict_sign(image):\n",
    "    # Preprocess the image\n",
    "    img_array = preprocess_image(image)\n",
    "    \n",
    "    # Predict the class\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class_idx = np.argmax(predictions[0])\n",
    "    predicted_class = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "    \n",
    "    return f\"Detected Sign: {predicted_class}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "gr.Interface(\n",
    "    fn=predict_sign,\n",
    "    inputs=gr.Image(type=\"pil\"),  # Accept image input as PIL format\n",
    "    outputs=gr.Textbox(),  # Output the detected sign in text format\n",
    "    title=\"Sign Language Detection\",\n",
    "    description=\"Upload an image containing a sign, and the model will predict the detected sign.\",\n",
    ").launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5967de-ae0c-41b4-8cf1-106fd063ec43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
